### 目录

- [ ] 01-01 个性化推荐算法课程导学.mp4
- [ ] 01-02 个性化推荐算法综述.mp4
- [ ] 01-03 个性化召回算法综述.mp4
- [ ] 02-01 LFM算法综述.mp4
- [ ] 02-02 LFM算法的理论基础与公式推导.mp4
- [ ] 02-03 基础工具函数的代码书写.mp4
- [ ] 02-04 LFM算法训练数据抽取.mp4
- [ ] 02-05 LFM模型训练.mp4
- [ ] 02-06 基于LFM的用户个性化推荐与推荐结果分析.mp4
- [ ] 03-01 personal rank算法的背景与物理意义.mp4
- [ ] 03-02 personal rank 算法的数学公式推导.mp4
- [ ] 03-03 代码构建用户物品二分图.mp4
- [ ] 03-04 代码实战personal rank算法的基础版本.mp4
- [ ] 03-05 代码实战personal rank算法矩阵版本上.mp4
- [ ] 04-01 item2vec算法的背景与物理意义.mp4
- [ ] 04-02 item2vec依赖模型word2vec之cbow数学原理介绍.mp4
- [ ] 04-03 item2vec依赖模型word2vec之skip gram数学原理介绍.mp4
- [ ] 04-04 代码生成item2vec模型所需训练数据.mp4
- [ ] 04-05 word2vec运行参数介绍与item embedding.mp4
- [ ] 04-06 基于item bedding产出物品相似度矩阵与item2vec推荐流程梳理.mp4
- [ ] 05-01 content based算法理论知识介绍.mp4
- [ ] 05-02 content based算法代码实战之工具函数的书写.mp4
- [ ] 05-03 用户刻画与基于内容推荐的代码实战。.mp4
- [ ] 06-01 个性化召回算法总结与评估方法的介绍。.mp4
- [ ] 07-01 学习排序综述.mp4
- [ ] 08-01 逻辑回归模型的背景知识介绍.mp4
- [ ] 08-02 逻辑回归模型的数学原理.mp4
- [ ] 08-03 样本选择与特征选择相关知识.mp4
- [ ] 08-04 代码实战LR之样本选择.mp4
- [ ] 08-05 代码实战LR之离散特征处理.mp4
- [ ] 08-06 代码实战LR之连续特征处理.mp4
- [ ] 08-07 LR模型的训练.mp4
- [ ] 08-08 LR模型在测试数据集上表现-上.mp4
- [ ] 08-09 LR模型在测试数据集上表现-下.mp4
- [ ] 08-10 LR模型训练之组合特征介绍.mp4
- [ ] 09-01 背景知识介绍之决策树.mp4
- [ ] 09-02 梯度提升树的数学原理与构建流程.mp4
- [ ] 09-03 xgboost数学原理介绍.mp4
- [ ] 09-04 gbdt与LR混合模型网络介绍.mp4
- [ ] 09-05 代码训练gbdt模型.mp4
- [ ] 09-06 gbdt模型最优参数选择.mp4
- [ ] 09-07 代码训练gbdt与LR混合模型.mp4
- [ ] 09-08 模型在测试数据集表现 上.mp4
- [ ] 09-09 模型在测试数据集表现 下.mp4
- [ ] 10-1 背景知识介绍之什么是深度学习.mp4
- [ ] 10-2 DNN网络结构与反向传播算法.mp4
- [ ] 10-3 wide and deep网络结构与数学原理介绍.mp4
- [ ] 10-4 .代码实战wd模型之wide侧与deep侧特征构建.mp4
- [ ] 10-5 代码实战wd模型之模型对象的构建.mp4
- [ ] 10-6 wd模型的训练与模型在测试数据集上的表现.mp4
- [ ] 11-1 学习排序部分总结与回顾.mp4
- [ ] 12-1 个性化推荐算法实战课程总结与回顾.mp4

#### 背景

- Item2Item的推荐方式效果显著

- 神经网络模型的特征抽象能力

  - 隐藏层和输出层之间的网络都是全连接层的网络
  - 激活函数的非线性化

-  Item2Vec-Neural Item Embedding for Collaborative Filtering

  - 提出了Item2Vec落地场景

  - Item2Vec 所选的model，负采样方法训练

  - 抽象了算法的总体流程

  - 实验对比

#### 物理意义

- word2vec模型:语料中的词embedding成词向量，词向量的远近表示词与词的远近
	- 三层的神经网络
- 将用户的行为序列转化成item组成的句子
  - 用户一系列的行为，item与item之间的关系，像文字所组成的句子一样
- 模仿word2vec 训练 word embedding，将item embedding
  - 提供语料也就是文字放入w2v，训练出来的embedding可以表示词的远近
  - item之间语义内涵的远近
  - item组成的语料 ->w2v ，完成tem embedding，得出的向量可以表示item之间的远近，相似性
  - 缺陷
    - 用户行为序列时序性缺失
    	- 用户的行为转换为序列，打乱或者不打乱结果差不多
    - 用户行为序列中的item的强度是无区分性的
    	- 观看80%，50%，都是一次，卖或者加购物车可能都是一次
- Item2Vec算法主流程
	- 从log中抽取用户行为序列
		- 不同推荐系统代表的行为不同，信息流-点击，评分系统-评分大于几分，电商系统-用户购买
	-  将行为序列当成语料训练word2vec得到item embedding
		- 模型有很多参数是要自己去设定的
	- 得到item sim关系用于推荐
- exmple
	![example](img/01.jpg)

#### Word2Vec Model

- CBOW(continuous bag of words)

  ![CBOW](img/02.jpg)

  - 输入，投影，输出
  - 5个词，输入的训练数据w和上下文，投影层将上下文输入的向量加起来，每个词都初始化了一个向量，投影与输出是全连接

- 

  - x<sub>w</sub>

- Skip Gram Word2vec数学原理

  - 

